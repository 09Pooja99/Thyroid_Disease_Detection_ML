{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set class distribution:\n",
      " negative           0.952679\n",
      "hyperthyroidism    0.044196\n",
      "hypothyroidism     0.003125\n",
      "Name: Class, dtype: float64\n",
      "\n",
      "Test set class distribution:\n",
      " negative           0.951786\n",
      "hyperthyroidism    0.044643\n",
      "hypothyroidism     0.003571\n",
      "Name: Class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df1=pd.read_csv(\"processed_data.csv\")\n",
    "\n",
    "target_column= \"Class\"\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(df1, df1[target_column]):\n",
    "    train_set = df1.loc[train_index]\n",
    "    test_set = df1.loc[test_index]\n",
    "\n",
    "print(\"Train set class distribution:\\n\", train_set[target_column].value_counts(normalize=True))\n",
    "print(\"\\nTest set class distribution:\\n\", test_set[target_column].value_counts(normalize=True))\n",
    "\n",
    "train_set.to_csv(\"train_data.csv\", index=False)\n",
    "test_set.to_csv(\"test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"train_data.csv\")\n",
    "test_set = pd.read_csv(\"test_data.csv\")\n",
    "target_column = \"Class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.drop(columns=[target_column])\n",
    "y_train = train_set[target_column]\n",
    "X_test = test_set.drop(columns=[target_column])\n",
    "y_test = test_set[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                            2\n",
       "sex                           92\n",
       "on thyroxine                   0\n",
       "query on thyroxine             0\n",
       "on antithyroid medication      0\n",
       "sick                           0\n",
       "pregnant                       0\n",
       "thyroid surgery                0\n",
       "I131 treatment                 0\n",
       "query hypothyroid              0\n",
       "query hyperthyroid             0\n",
       "lithium                        0\n",
       "goitre                         0\n",
       "tumor                          0\n",
       "hypopituitary                  0\n",
       "psych                          0\n",
       "TSH                          228\n",
       "T3                           461\n",
       "TT4                          151\n",
       "T4U                          234\n",
       "FTI                          232\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = X_train.select_dtypes(include=[np.number]).columns\n",
    "cat_cols = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "\n",
    "num_transformer = SimpleImputer(strategy=\"median\")\n",
    "cat_transformer = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "\n",
    "# Apply transformations using ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_transformer, num_cols),\n",
    "    (\"cat\", cat_transformer, cat_cols)\n",
    "])\n",
    "\n",
    "# Fit and transform training data\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Get new column names after encoding\n",
    "encoded_cat_cols = preprocessor.named_transformers_['cat'].get_feature_names_out(cat_cols)\n",
    "all_cols = list(num_cols) + list(encoded_cat_cols)\n",
    "\n",
    "# Convert transformed arrays into DataFrames\n",
    "X_train = pd.DataFrame(X_train_transformed, columns=all_cols, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_transformed, columns=all_cols, index=X_test.index)\n",
    "\n",
    "print(\"Preprocessing complete! New shape of X_train:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.hist(bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(X_test[\"TT4\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Log transform TSH to handle extreme skewness\n",
    "X_train.loc[:, 'TSH'] = np.log1p(X_train['TSH'])\n",
    "X_test.loc[:, 'TSH'] = np.log1p(X_test['TSH'])\n",
    "\n",
    "# Choose scalers based on distribution\n",
    "scalers = {\n",
    "    'age': StandardScaler(),\n",
    "    'TSH': RobustScaler(),   # After log transformation\n",
    "    'TT4': RobustScaler(),\n",
    "    'T4U': MinMaxScaler(),\n",
    "    'FTI': MinMaxScaler(),\n",
    "    'T3': RobustScaler()\n",
    "}\n",
    "\n",
    "# Apply appropriate scaling\n",
    "for col, scaler in scalers.items():\n",
    "    X_train[col] = scaler.fit_transform(X_train[[col]]).flatten()\n",
    "    X_test[col] = scaler.transform(X_test[[col]]).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check class distribution\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class distribution\n",
    "sns.countplot(x=y_train)\n",
    "plt.title(\"Class Distribution in Training Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minority_class = y_train.value_counts().min()\n",
    "majority_class = y_train.value_counts().max()\n",
    "\n",
    "imbalance_ratio = majority_class / minority_class\n",
    "print(f\"Class Imbalance Ratio: {imbalance_ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check new class distribution\n",
    "print(y_train_resampled.value_counts())\n",
    "\n",
    "# Plot new class distribution\n",
    "sns.countplot(x=y_train_resampled)\n",
    "plt.title(\"Balanced Class Distribution (After Oversampling)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled=pd.DataFrame(data=X_train_resampled, columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check new class distribution\n",
    "print(\"Class distribution after SMOTE:\\n\", y_train_smote.value_counts())\n",
    "\n",
    "# Plot class distribution after SMOTE\n",
    "sns.countplot(x=y_train_smote)\n",
    "plt.title(\"Balanced Class Distribution (After SMOTE)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##SMOTE vs. Random Oversampling\n",
    "\n",
    "✔ Both techniques balance the dataset, but SMOTE is usually better as it generates synthetic data rather than duplicating samples.\n",
    "\n",
    "✔ Random Oversampling might cause overfitting, as the model sees the same minority samples multiple times.\n",
    "\n",
    "✔ SMOTE reduces overfitting risk by creating new synthetic points instead of copying existing ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare SMOTE vs. Random Oversampling by training a model on both resampled datasets and evaluating their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Steps to Compare\n",
    "\n",
    "\n",
    "Train a classifier (e.g., Random Forest, Logistic Regression) on:\n",
    "\n",
    "-Random Oversampling data \n",
    "\n",
    "-SMOTE data\n",
    "\n",
    "Evaluate using:\n",
    "\n",
    "-Accuracy\n",
    "\n",
    "-Precision, Recall, F1-score\n",
    "\n",
    "-Confusion Matrix\n",
    "\n",
    "Compare results to see which technique performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize classifiers\n",
    "model_ros = RandomForestClassifier(random_state=42)\n",
    "model_smote = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Apply Random Oversampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train models\n",
    "model_ros.fit(X_train_ros, y_train_ros)\n",
    "model_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predictions\n",
    "y_pred_ros = model_ros.predict(X_test)\n",
    "y_pred_smote = model_smote.predict(X_test)\n",
    "\n",
    "# Evaluate Random Oversampling\n",
    "print(\"=== Random Oversampling Results ===\")\n",
    "print(classification_report(y_test, y_pred_ros))\n",
    "print(\"Confusion Matrix (Random Oversampling):\")\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_ros), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - Random Oversampling\")\n",
    "plt.show()\n",
    "\n",
    "# Evaluate SMOTE\n",
    "print(\"=== SMOTE Results ===\")\n",
    "print(classification_report(y_test, y_pred_smote))\n",
    "print(\"Confusion Matrix (SMOTE):\")\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_smote), annot=True, fmt=\"d\", cmap=\"Greens\")\n",
    "plt.title(\"Confusion Matrix - SMOTE\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check new class distribution\n",
    "print(y_train_resampled.value_counts())\n",
    "\n",
    "# Plot new class distribution\n",
    "sns.countplot(x=y_train_resampled)\n",
    "plt.title(\"Balanced Class Distribution (After Oversampling)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE improved recall for hyperthyroidism (from 72% to 80%) but at the cost of slightly reduced precision.\n",
    "\n",
    "Hypothyroidism remains a challenge (recall stuck at 50%), meaning the model still struggles with extremely rare cases.\n",
    "\n",
    "Negative class performance is slightly reduced but remains excellent.\n",
    "\n",
    "Overall accuracy remains the same (98%), indicating SMOTE didn't drastically change the overall performance but helped with class balance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1️⃣ we will Use SMOTE for Hypothyroidism + Random Oversampling for Hyperthyroidism\n",
    "2️⃣ Experiment with XGBoost, Random Forest, and SVM\n",
    "\n",
    "3️⃣ Evaluate results & fine-tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install imbalanced-learn xgboost scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"TSH\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'Strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20496\\2867452219.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Handle missing values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mnum_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"median\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mcat_transformer\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mSimpleImputer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStrategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"most_frequent\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mcat_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'Strategy'"
     ]
    }
   ],
   "source": [
    "# Identify numerical and categorical columns\n",
    "num_cols = X_train.select_dtypes(include=[np.number]).columns\n",
    "cat_cols = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Handle missing values\n",
    "num_transformer = SimpleImputer(strategy=\"median\")\n",
    "cat_transformer =SimpleImputer(Strategy=\"most_frequent\")\n",
    "cat_transformer = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "X_train[num_cols] = num_transformer.fit_transform(X_train[num_cols])\n",
    "X_test[num_cols] = num_transformer.transform(X_test[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['TSH'].fillna(X_train['TSH'].median(), inplace=True)\n",
    "X_test['TSH'].fillna(X_train['TSH'].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"TSH\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transform TSH to handle extreme skewness\n",
    "X_train.loc[:, 'TSH'] = np.log1p(X_train['TSH'])\n",
    "X_test.loc[:, 'TSH'] = np.log1p(X_test['TSH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                           0\n",
       "sex                          92\n",
       "on thyroxine                  0\n",
       "query on thyroxine            0\n",
       "on antithyroid medication     0\n",
       "sick                          0\n",
       "pregnant                      0\n",
       "thyroid surgery               0\n",
       "I131 treatment                0\n",
       "query hypothyroid             0\n",
       "query hyperthyroid            0\n",
       "lithium                       0\n",
       "goitre                        0\n",
       "tumor                         0\n",
       "hypopituitary                 0\n",
       "psych                         0\n",
       "TSH                           0\n",
       "T3                            0\n",
       "TT4                           0\n",
       "T4U                           0\n",
       "FTI                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "X_train still contains NaN values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20496\\3186246420.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Final check before resampling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"X_train still contains NaN values!\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"X_train contains infinite values!\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: X_train still contains NaN values!"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Choose scalers based on distribution\n",
    "scalers = {\n",
    "    'age': StandardScaler(),\n",
    "    'TSH': RobustScaler(),   # After log transformation\n",
    "    'TT4': RobustScaler(),\n",
    "    'T4U': MinMaxScaler(),\n",
    "    'FTI': MinMaxScaler(),\n",
    "    'T3': RobustScaler()\n",
    "}\n",
    "\n",
    "# Apply appropriate scaling\n",
    "for col, scaler in scalers.items():\n",
    "    X_train[col] = scaler.fit_transform(X_train[[col]]).flatten()\n",
    "    X_test[col] = scaler.transform(X_test[[col]]).flatten()\n",
    "\n",
    "# Final check before resampling\n",
    "assert not X_train.isnull().values.any(), \"X_train still contains NaN values!\"\n",
    "assert np.isfinite(X_train).all().all(), \"X_train contains infinite values!\"\n",
    "\n",
    "# Reset indices to avoid misalignment issues\n",
    "#y_train = y_train.reset_index(drop=True)\n",
    "#X_train = X_train.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"TSH\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE for hypothyroidism and Random Oversampling for hyperthyroidism\n",
    "smote = SMOTE(sampling_strategy={\"hypothyroidism\": \"auto\"}, random_state=42)\n",
    "ros = RandomOverSampler(sampling_strategy={\"hyperthyroidism\": \"auto\"}, random_state=42)\n",
    "\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_resampled, y_resampled)\n",
    "\n",
    "# Convert back to DataFrame\n",
    "X_train_balanced = pd.DataFrame(X_resampled, columns=X_train.columns)\n",
    "y_train_balanced = pd.Series(y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = X_train.select_dtypes(include=[np.number]).columns\n",
    "cat_cols = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "\n",
    "num_transformer = SimpleImputer(strategy=\"median\")\n",
    "cat_transformer = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "\n",
    "# Apply transformations using ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_transformer, num_cols),\n",
    "    (\"cat\", cat_transformer, cat_cols)\n",
    "])\n",
    "\n",
    "# Fit and transform training data\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Get new column names after encoding\n",
    "encoded_cat_cols = preprocessor.named_transformers_['cat'].get_feature_names_out(cat_cols)\n",
    "all_cols = list(num_cols) + list(encoded_cat_cols)\n",
    "\n",
    "# Convert transformed arrays into DataFrames\n",
    "X_train = pd.DataFrame(X_train_transformed, columns=all_cols, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_transformed, columns=all_cols, index=X_test.index)\n",
    "\n",
    "print(\"Preprocessing complete! New shape of X_train:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Log transform TSH to handle extreme skewness\n",
    "X_train.loc[:, 'TSH'] = np.log1p(X_train['TSH'])\n",
    "X_test.loc[:, 'TSH'] = np.log1p(X_test['TSH'])\n",
    "\n",
    "# Choose scalers based on distribution\n",
    "scalers = {\n",
    "    'age': StandardScaler(),\n",
    "    'TSH': RobustScaler(),   # After log transformation\n",
    "    'TT4': RobustScaler(),\n",
    "    'T4U': MinMaxScaler(),\n",
    "    'FTI': MinMaxScaler(),\n",
    "    'T3': RobustScaler()\n",
    "}\n",
    "\n",
    "# Apply appropriate scaling\n",
    "for col, scaler in scalers.items():\n",
    "    X_train[col] = scaler.fit_transform(X_train[[col]]).flatten()\n",
    "    X_test[col] = scaler.transform(X_test[[col]]).flatten()\n",
    "\n",
    "# Combine features and target for resampling\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "\n",
    "# Apply SMOTE for hypothyroidism and Random Oversampling for hyperthyroidism\n",
    "smote = SMOTE(sampling_strategy={\"hypothyroidism\": \"auto\"}, random_state=42)\n",
    "ros = RandomOverSampler(sampling_strategy={\"hyperthyroidism\": \"auto\"}, random_state=42)\n",
    "\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_resampled, y_resampled)\n",
    "\n",
    "# Convert back to DataFrame\n",
    "X_train_balanced = pd.DataFrame(X_resampled, columns=X_train.columns)\n",
    "y_train_balanced = pd.Series(y_resampled)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
